<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Nevaniah Gounden | Optimisation Techniques</title>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <header class="subheader">
    <h1>Nevaniah Gounden</h1>
    <p class="subtitle">Optimisation Techniques for Rational Closure</p>
  </header>

  <main>
    <!-- ABSTRACT -->
    <section>
      <h2>Abstract</h2>
      <p>
        This project investigates how the computational efficiency of <strong>Rational Closure</strong> (RC) in
        <em>defeasible reasoning</em> can be improved without affecting logical soundness. RC provides a way for
        artificial intelligence systems to reason about exceptions and uncertainty, but its sequential nature
        limits scalability. Three optimisation techniques were implemented: <strong>parallelisation</strong>,
        <strong>sub-query memoization</strong>, and <strong>multi-rank traversal</strong>. The aim was to reduce runtime across
        knowledge bases of increasing size and complexity. Performance testing showed significant runtime improvements, typically
        between 80% and 95%, varying by knowledge base size and query complexity.

      </p>
    </section>

    <!-- INTRODUCTION -->
    <section>
      <h2>Introduction & Aims</h2>
      <p>
        RC provides a structured approach for drawing cautious conclusions when information
        contains exceptions. Although theoretically correct, RC’s sequential entailment checks make it slow for
        large knowledge bases. This work aims to:
      </p>
      <ul>
        <li>Optimise RC’s runtime performance through targeted computational enhancements.</li>
        <li>Preserve the algorithm’s integrity and logical correctness during optimisation.</li>
        <li>Evaluate scalability across different dataset sizes and query types.</li>
      </ul>
      <p>
        By applying parallelisation, sub-query memoization, and adaptive traversal methods, the study sought to make
        Rational Closure practical for large-scale reasoning in explainable AI systems.
      </p>
    </section>

    <!-- RELATED WORK -->
    <section>
      <h2>Related Work</h2>
      <p>
        Prior implementations of Rational Closure relied on sequential entailment, as first formalised by
        Lehmann and Magidor. Although sound, these versions suffered from exponential time growth as knowledge
        bases increased in complexity. Later work by Casini, Giordano, and Straccia introduced syntactic and
        semantic improvements but retained the sequential core. Recent studies explored scalability through
        caching, distributed computing, and graphical reasoning tools, yet few directly addressed optimisation
        of RC’s core execution loop. This project builds upon these foundations by experimentally comparing
        multiple optimisation strategies under identical conditions to evaluate both correctness and efficiency.
      </p>
    </section>

    <!-- OPTIMISATION TECHNIQUES -->
    <section>
      <h2>Optimisation Techniques</h2>

      <h3>1. Parallelisation</h3>
        <p><em>What it is.</em> Parallelisation allows the algorithm to check several queries at the same time instead of one after another. Each query runs independently on a separate processor core, ensuring consistent and correct results.</p>

        <p><em>What we observed.</em> This approach provided substantial time savings once the knowledge base was large enough to make each query costly. Across medium to large test cases, parallelisation reduced total runtime by roughly <strong>83–89%</strong> compared to sequential execution, without changing the logical outcomes. However, on very small or simple workloads, the extra coordination between threads slightly reduced efficiency.</p>

        <p><em>Bottom line.</em> Parallelisation is highly effective for large or complex workloads and provides the greatest performance boost when combined with caching (memoization). For smaller datasets, the benefits are limited due to overhead.</p>

      <h3>2. Sub-query Memoization</h3>
        <p><em>What it is.</em> Memoization stores the results of previous logical checks so they can be reused later instead of recalculated. Each result is linked to a unique “signature” of the query and its knowledge base, guaranteeing accuracy even when many queries run in parallel.</p>

        <p><em>What we observed.</em> This technique cut execution time by <strong>40–46%</strong> for workloads containing repeated or partially overlapping queries. It performed best when queries shared common patterns, as the system could reuse earlier results. On completely unique queries, the effect was minimal, and in some cases neutral, since there were no results to reuse.</p>

        <p><em>Bottom line.</em> Memoization is most valuable when queries overlap or repeat. When combined with parallelisation, it produces the fastest and most scalable configuration overall.</p>

      <h3>3. Multi-Rank Traversal</h3>
        <p><em>What it is.</em> Instead of moving through ranks one by one, we tested adaptive “jumping” strategies (binary and ternary) that skip ahead to different parts of the ranked structure to reduce the number of checks needed.</p>

        <p><em>What we observed.</em> In most cases, the ranked knowledge bases were shallow, meaning there weren’t many ranks to explore. The main cost came from the logical checks themselves, not from walking through the ranks. Because of this, the adaptive methods—while theoretically faster—added unnecessary branching and bookkeeping, making them <strong>slower than simple linear traversal</strong>. Once caching (memoization) and parallelisation were enabled, the order of traversal had almost no effect.</p>

        <p><em>Bottom line.</em> Multi-rank traversal rarely improved performance and occasionally slowed it down. It remains available for unusually deep knowledge bases, but the recommended setup for best speed and efficiency is <strong>linear traversal with memoization and parallelisation</strong>.</p>

      <div class="image-container">
        <img src="Images/results.png" alt="Graph showing optimisation results" class="results-graph">
        <p class="caption">Figure: Comparative runtime performance of optimisation techniques.</p>
      </div>
    </section>

    <!-- CONCLUSION -->
    <section>
      <h2>Conclusion</h2>
      <p>
        The combined use of parallelisation, caching, and adaptive traversal produced substantial performance
        improvements without altering logical outcomes. The best-performing configurations paired
        <strong>parallelisation</strong> with <strong>sub-query memoization</strong>, achieving substantially faster execution
        relative to the baseline. These findings demonstrate that Rational Closure, a foundational logic for
        defeasible reasoning, can be efficiently scaled for practical AI applications without sacrificing
        correctness.
      </p>
    </section>

    <p><a href="index.html" class="back-link">← Back to Project Home</a></p>
  </main>

  <footer>
    <p>&copy; 2025 EXTRC Project | University of Cape Town</p>
  </footer>
</body>
</html>
